
# ==========================================
# voice_synthesizer.py
# ==========================================

import openai
import os
from typing import Dict

class VoiceSynthesizer:
    def __init__(self):
        self.api_key = os.getenv("OPENAI_API_KEY")
        openai.api_key = self.api_key
        
        # è¯­éŸ³é£æ ¼æ˜ å°„
        self.voice_styles = {
            "companion": {"voice": "alloy", "speed": 1.0},
            "storyteller": {"voice": "onyx", "speed": 0.95},
            "energetic": {"voice": "nova", "speed": 1.1},
            "calm": {"voice": "shimmer", "speed": 0.9},
            "professional": {"voice": "echo", "speed": 1.0}
        }
    
    async def synthesize(
        self,
        text: str,
        emotion: str,
        age_group: str,
        voice_style: str = "companion"
    ) -> Dict:
        """åˆæˆå¸¦æƒ…æ„Ÿçš„è¯­éŸ³"""
        
        # æ ¹æ®æƒ…æ„Ÿè°ƒæ•´æ–‡æœ¬
        adjusted_text = self._adjust_text_for_emotion(text, emotion)
        
        # é€‰æ‹©åˆé€‚çš„è¯­éŸ³
        voice_config = self.voice_styles.get(
            voice_style,
            self.voice_styles["companion"]
        )
        
        # æ ¹æ®å¹´é¾„è°ƒæ•´
        if age_group == "child":
            voice_config["voice"] = "nova"
            voice_config["speed"] = 1.0
        elif age_group == "teen":
            voice_config["voice"] = "alloy"
            voice_config["speed"] = 1.05
        
        # è°ƒç”¨OpenAI TTS
        response = await openai.Audio.acreate(
            model="tts-1",
            input=adjusted_text,
            voice=voice_config["voice"],
            speed=voice_config["speed"]
        )
        
        # è¿™é‡Œåº”è¯¥ä¿å­˜éŸ³é¢‘æ–‡ä»¶å¹¶è¿”å›URL
        # ç®€åŒ–ç‰ˆæœ¬,è¿”å›æ¨¡æ‹Ÿæ•°æ®
        
        return {
            "url": f"https://api.example.com/audio/{hash(text)}.mp3",
            "duration": len(text) * 0.1,  # ç²—ç•¥ä¼°ç®—
            "format": "mp3",
            "voice": voice_config["voice"],
            "speed": voice_config["speed"]
        }
    
    def _adjust_text_for_emotion(self, text: str, emotion: str) -> str:
        """æ ¹æ®æƒ…æ„Ÿè°ƒæ•´æ–‡æœ¬è¯­æ°”"""
        
        # å¯ä»¥æ·»åŠ è¯­æ°”è¯ã€è¡¨æƒ…ç­‰
        emotion_markers = {
            "happy": "ğŸ˜Š ",
            "excited": "ğŸ‰ ",
            "sad": "",
            "calm": "",
            "angry": "",
            "anxious": ""
        }
        
        marker = emotion_markers.get(emotion, "")
        return f"{marker}{text}"